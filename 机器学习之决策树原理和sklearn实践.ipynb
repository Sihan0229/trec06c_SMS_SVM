{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 场景描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间：早上八点，地点：婚介所\n",
    "\n",
    "‘闺女，我有给你找了个合适的对象，今天要不要见一面？’\n",
    "\n",
    "‘多大？’ ‘26岁’\n",
    "\n",
    "‘长的帅吗？’ ‘还可以，不算太帅’\n",
    "\n",
    "‘工资高吗？’  ‘略高于平均水平’\n",
    "\n",
    "‘会写代码吗？’  ‘人家是程序员，代码写的棒着呢！’\n",
    "\n",
    "‘好，把他的联系方式发过来吧，我抽空见一面’\n",
    "\n",
    "上面的场景描述<b>摘抄自<百面机器学习></b>，是一个典型的决策树分类问题，通过年龄、长相、工资、是否会编程等特征属性对介绍对象进行是否约会进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树是一种自上而下，对样本数据进行树形分类的过程，由结点和有向边组成，每个结点(叶结点除外)便是一个特征或属性，叶结点表示类别。从顶部根结点开始，所有样本聚在仪器，经过根结点的划分，样本被分到不同的子结点中。再根据子结点的特征进一步划分，直至样本都被分到某一类别(叶子结点)中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树作为最基础、最常见的有监督学习模型，常被用于分类问题和回归问题，将决策树应用集成思想可以得到随机森林、梯度提升决策树等模型。其主要优点是模型具有可读性，分类速度快。决策树的学习通常包括三个步骤：特征选择、决策树的生成和决策树的修剪，下面对特征选择算法进行描述和区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3---最大信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的度量，设X是一个取有限个值的随机变量，其概率分布为：$$P(X=X_i)=P_i (i = 1,2,...,n)$$,则随机变量X的熵定义为：$$H(X) = -\\sum_{i=1}^np_i\\log{p_i}$$表达式中的对数以2为底或以e为底，这时熵的单位分别称作bit或nat,从表达式可以看出X的熵与X的取值无关，所以X的熵也记作$H(p)$,即$$H(p) = -\\sum_{x=1}^np_i\\log{p_i}$$熵取值越大，随机变量的不确定性越大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件熵：\n",
    "    \n",
    "条件熵H(Y|X)表示在已知随机变量X的条件下，随机变量Y的不确定性，随机变量X给定的条件下随机变量Y的条件熵定义为X给定条件下Y的条件概率分布的熵对X的数学期望$$H(Y|X) = \\sum_{i=1}^nP(X=X_i)H(Y|X=X_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益：$$g(D,A) = H(D) - H(D|A)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    年龄  长相  工资 写代码  类别\n",
      "小A   老   帅   高  不会  不见\n",
      "小B  年轻  一般  中等   会   见\n",
      "小C  年轻   丑   高  不会  不见\n",
      "小D  年轻  一般   高   会   见\n",
      "小L  年轻  一般   低  不会  不见\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "        '年龄':['老','年轻','年轻','年轻','年轻'],\n",
    "        '长相':['帅','一般','丑','一般','一般'],\n",
    "        '工资':['高','中等','高','高','低'],\n",
    "        '写代码':['不会','会','不会','会','不会'],\n",
    "        '类别':['不见','见','不见','见','不见']}\n",
    "frame = pd.DataFrame(data,index=['小A','小B','小C','小D','小L'])\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5108256237659907\n",
      "H(D): 0.9709505944546686\n",
      "H(D|年龄) 0.8\n",
      "以同样的方法计算H(D|长相),H(D|工资),H(D|写代码)\n",
      "H(D|长相) 0.551\n",
      "H(D|工资) 0.551\n",
      "H(D|写代码) 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(3/5))\n",
    "print('H(D):',-3/5 *math.log(3/5,2) - 2/5*math.log(2/5,2))\n",
    "print('H(D|年龄)',1/5*math.log(1,2)+4/5*(-1/2*math.log(1/2,2)-1/2*math.log(1/2,2)))\n",
    "print('以同样的方法计算H(D|长相),H(D|工资),H(D|写代码)')\n",
    "print('H(D|长相)',0.551)\n",
    "print('H(D|工资)',0.551)\n",
    "print('H(D|写代码)',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算信息增益：g(D,写代码)=0.971最大，可以先按照写代码来拆分决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5---最大信息增益比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的问题，使用信息增益比可以对对着问题进行校正，这是特征选择的另一标准\n",
    "信息增益比定义为其信息增益g(D,A)与训练数据集D关于特征A的值的熵$H_A(D)$之比：$$g_R(D,A) = \\frac{g(D,A)}{H_A(D)}$$\n",
    "\n",
    "$$H_A(D) = -\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\log\\frac{|D_i|}{|D|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿上面ID3的例子说明：\n",
    "$$H_年龄(D) = -1/5*math.log(1/5,2)-4/5*math.log(4/5,2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g_R(D,年龄) = H_{年龄}(D)/g(D,年龄) = 0.171/0.722 = 0.236 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART----最大基尼指数(Gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini描述的是数据的纯度，与信息熵含义类似,分类问题中，假设有K个类，样本点数据第k类的概率为$P_k$,则概率分布的基尼指数定义为：\n",
    "$$Gini(p) = 1- \\sum_{k=1}^Kp_k(1-p_k) = 1 - \\sum_{k=1}^Kp_{k}^2$$\n",
    "对于二分类问题，弱样本点属于第1个类的概率是p,则概率分布的基尼指数为$$Gini(p) = 2p(1-p)$$,对于给定的样本几何D,其基尼指数为$$Gini(D) = 1 - \\sum_{k=1}^K[\\frac{|C_k|}{|D|}]^2$$注意这里$C_k$是D种属于第k类的样本子集，K是类的个数,如果样本几个D根据特征A是否取某一可能指a被分割成D1和D2两部分，则在特征A的条件下，集合D的基尼指数定义为$$Gini(D,A) = \\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)$$\n",
    "$$Gini(D|年龄=老)=1/5*（1-1）+4/5*[1-(1/2*1/2+1/2*1/2)] = 0.4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART在每一次迭代种选择基尼指数最小的特征及其对应的切分点进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3、C4.5与Gini的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从样本类型角度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从样本类型角度，ID3只能处理离散型变量，而C4.5和CART都处理连续性变量，C4.5处理连续性变量时，通过对数据排序之后找到类别不同的分割线作为切割点，根据切分点把连续型数学转换为bool型，从而将连续型变量转换多个取值区间的离散型变量。而对于CART，由于其构建时每次都会对特征进行二值划分，因此可以很好地适合连续性变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从应用角度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3和C4.5只适用于分类任务，而CART既可以用于分类也可以用于回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从实现细节、优化等角度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3对样本特征缺失值比较敏感，而C4.5和CART可以对缺失值进行不同方式的处理，ID3和C4.5可以在每个结点熵产生出多叉分支，且每个特征在层级之间不会复用，而CART每个结点只会产生两个分支，因此会形成一颗二叉树，且每个特征可以被重复使用；ID3和C4.5通过剪枝来权衡树的准确性和泛化能力，而CART直接利用全部数据发现所有可能的树结构进行对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么要进行剪枝？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对决策树进行剪枝是为了防止过拟合\n",
    "\n",
    "根据决策树生成算法通过训练数据集生成了复杂的决策树，导致对于测试数据集出现了过拟合现象，为了解决过拟合，就必须考虑决策树的复杂度，对决策树进行剪枝，剪掉一些枝叶，提升模型的泛化能力\n",
    "\n",
    "决策树的剪枝通常由两种方法，预剪枝和后剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预剪枝的核心思想是在树中结点进行扩展之前，先计算当前的划分是否能带来模型泛化能力的提升，如果不能，则不再继续生长子树。此时可能存在不同类别的样本同时存于结点中，按照多数投票的原则判断该结点所属类别。预剪枝对于何时停止决策树的生长有以下几种方法\n",
    "\n",
    "- (1)当树达到一定深度的时候，停止树的生长\n",
    "- (2)当叶结点数到达某个阈值的时候，停止树的生长\n",
    "- (3)当到达结点的样本数量少于某个阈值的时候，停止树的生长\n",
    "- (4)计算每次分裂对测试集的准确度提升，当小于某个阈值的时候，不再继续扩展\n",
    "\n",
    "预剪枝思想直接，算法简单，效率高特点，适合解决大规模问题。但如何准确地估计何时停止树的生长，针对不同问题会有很大差别，需要一定的经验判断。且预剪枝存在一定的局限性，有欠拟合的风险"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后剪枝的核心思想是让算法生成一颗完全生长的决策树，然后从底层向上计算是否剪枝。剪枝过程将子树删除，用一个叶结点代替，该结点的类别同样按照多数投票原则进行判断。同样地，后剪枝叶可以通过在测试集上的准确率进行判断，如果剪枝过后的准确率有所提升，则进行剪枝，后剪枝方法通常可以得到泛化能力更强的决策树，但时间开销更大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C_a(T) = \\sum_{t=1}^{|T|}N_tH_t(T) + a|T|$$\n",
    "\n",
    "$其中|T|为叶结点个数，N_t为结点t的样本个数，H_t(T)为结点t的信息熵，a|T|为惩罚项，a>=0$\n",
    "\n",
    "$$C_a(T) = \\sum_{t=1}^{|T|}N_tH_t(T) + a|T| = -\\sum_{t=1}^{|T|}\\sum_{k=1}^KN_{tk}\\log \\frac{N_{tk}}{N_t} + a|T|$$\n",
    "\n",
    "注意：上面的公式中是$N_{tk}\\log \\frac{N_{tk}}{N_t}$,而不是$\\frac{N_{tk}}{N_t} \\log \\frac{N_{tk}}{N_t}$\n",
    "\n",
    "令：$$C_a(T) = C(T) + a|T|$$\n",
    "\n",
    "$C(T)$表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，|T|表示模型复杂度，参数a>=0控制两者的影响力，较大的a促使选择较简单的模型，较小的a促使选择复杂的模型，a=0意味着只考虑模型与训练数据的拟合程度，不考虑模型的复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用sklearn库为卫星数据集训练并微调一个决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a.使用make_moons(n_samples=10000,noise=0.4)生成一个卫星数据集\n",
    "- b.使用train_test_split()拆分训练集和测试集\n",
    "- c.使用交叉验证的网格搜索为DecisionTreeClassifier找到合适的超参数，提示:尝试max_leaf_nodes的多种值\n",
    "- d.使用超参数对整个训练集进行训练，并测量模型测试集上的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(array([[ 0.24834453, -0.11160162],\n",
      "       [-0.34658051, -0.43774172],\n",
      "       [-0.25009951, -0.80638312],\n",
      "       ...,\n",
      "       [ 2.3278198 ,  0.39007769],\n",
      "       [-0.77964208,  0.68470383],\n",
      "       [ 0.14500963,  1.35272533]]), array([1, 1, 1, ..., 1, 0, 0], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "dataset = make_moons(n_samples=10000,noise=0.4)\n",
    "print(type(dataset))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2) (10000,)\n"
     ]
    }
   ],
   "source": [
    "dataset_array = np.array(dataset[0])\n",
    "label_array = np.array(dataset[1])\n",
    "print(dataset_array.shape,label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2) (2000, 2)\n",
      "(8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# 拆分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test = train_test_split(dataset_array,test_size=0.2,random_state=42)\n",
    "print(x_train.shape,x_test.shape)\n",
    "y_train,y_test = train_test_split(label_array,test_size=0.2,random_state=42)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] max_leaf_nodes=2 ................................................\n",
      "[CV] ................................. max_leaf_nodes=2, total=   0.0s\n",
      "[CV] max_leaf_nodes=2 ................................................\n",
      "[CV] ................................. max_leaf_nodes=2, total=   0.0s\n",
      "[CV] max_leaf_nodes=2 ................................................\n",
      "[CV] ................................. max_leaf_nodes=2, total=   0.0s\n",
      "[CV] max_leaf_nodes=3 ................................................\n",
      "[CV] ................................. max_leaf_nodes=3, total=   0.0s\n",
      "[CV] max_leaf_nodes=3 ................................................\n",
      "[CV] ................................. max_leaf_nodes=3, total=   0.0s\n",
      "[CV] max_leaf_nodes=3 ................................................\n",
      "[CV] ................................. max_leaf_nodes=3, total=   0.0s\n",
      "[CV] max_leaf_nodes=4 ................................................\n",
      "[CV] ................................. max_leaf_nodes=4, total=   0.0s\n",
      "[CV] max_leaf_nodes=4 ................................................\n",
      "[CV] ................................. max_leaf_nodes=4, total=   0.0s\n",
      "[CV] max_leaf_nodes=4 ................................................\n",
      "[CV] ................................. max_leaf_nodes=4, total=   0.0s\n",
      "[CV] max_leaf_nodes=5 ................................................\n",
      "[CV] ................................. max_leaf_nodes=5, total=   0.0s\n",
      "[CV] max_leaf_nodes=5 ................................................\n",
      "[CV] ................................. max_leaf_nodes=5, total=   0.0s\n",
      "[CV] max_leaf_nodes=5 ................................................\n",
      "[CV] ................................. max_leaf_nodes=5, total=   0.0s\n",
      "[CV] max_leaf_nodes=6 ................................................\n",
      "[CV] ................................. max_leaf_nodes=6, total=   0.0s\n",
      "[CV] max_leaf_nodes=6 ................................................\n",
      "[CV] ................................. max_leaf_nodes=6, total=   0.0s\n",
      "[CV] max_leaf_nodes=6 ................................................\n",
      "[CV] ................................. max_leaf_nodes=6, total=   0.0s\n",
      "[CV] max_leaf_nodes=7 ................................................\n",
      "[CV] ................................. max_leaf_nodes=7, total=   0.0s\n",
      "[CV] max_leaf_nodes=7 ................................................\n",
      "[CV] ................................. max_leaf_nodes=7, total=   0.0s\n",
      "[CV] max_leaf_nodes=7 ................................................\n",
      "[CV] ................................. max_leaf_nodes=7, total=   0.0s\n",
      "[CV] max_leaf_nodes=8 ................................................\n",
      "[CV] ................................. max_leaf_nodes=8, total=   0.0s\n",
      "[CV] max_leaf_nodes=8 ................................................\n",
      "[CV] ................................. max_leaf_nodes=8, total=   0.0s\n",
      "[CV] max_leaf_nodes=8 ................................................\n",
      "[CV] ................................. max_leaf_nodes=8, total=   0.0s\n",
      "[CV] max_leaf_nodes=9 ................................................\n",
      "[CV] ................................. max_leaf_nodes=9, total=   0.0s\n",
      "[CV] max_leaf_nodes=9 ................................................\n",
      "[CV] ................................. max_leaf_nodes=9, total=   0.0s\n",
      "[CV] max_leaf_nodes=9 ................................................\n",
      "[CV] ................................. max_leaf_nodes=9, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用交叉验证的网格搜索为DecisionTreeClassifier找到合适的超参数\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(criterion='gini')\n",
    "param_grid = {'max_leaf_nodes': [i for i in range(2,10)]}\n",
    "gridSearchCV = GridSearchCV(decisionTree,param_grid=param_grid,cv=3,verbose=2)\n",
    "gridSearchCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_leaf_nodes': 4}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearchCV.best_params_)\n",
    "decision_tree = gridSearchCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8455\n"
     ]
    }
   ],
   "source": [
    "# 使用测试集对模型进行评估\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_prab = gridSearchCV.predict(x_test)\n",
    "print('accuracy_score:',accuracy_score(y_test,y_prab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(decision_tree,\n",
    "               out_file='./tree.dot',\n",
    "               rounded = True,\n",
    "               filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>生成tree.dot文件，然后使用dot命令$$dot -Tpng tree.dot -o decisontree_moons.png$$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./datasets/decisiontree_moons.png' width=600 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.tree.DecisionTreeClassifier类说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecsisionTreeClassifier类参数说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ui>\n",
    "    <li><b>criterion</b>: 特征选择方式，string,('gini' or 'entropy'),default='gini'</li>\n",
    "    <li><b>splitter</b>: 每个结点的拆分策略，('best' or 'random'),string,default='best'</li>\n",
    "    <li><b>max_depth</b>: int,default=None</li>\n",
    "    <li><b>min_samples_split</b>: int,float,default=2,分割前所需的最小样本数</li>\n",
    "    <li><b>min_samples_leaf</b>: </li>\n",
    "    <li><b>min_weight_fraction_leaf</b>: </li>\n",
    "    <li><b>max_features</b>: </li>\n",
    "    <li><b>random_state</b>: </li>\n",
    "    <li><b>max_leaf_nodes</b>: </li>\n",
    "    <li><b>min_impurity_decrease</b>: </li>\n",
    "    <li><b>min_impurity_split</b>: </li>\n",
    "    <li><b>class_weight</b>: </li>\n",
    "    <li><b>presort</b>: bool,default=False,对于小型数据集(几千个以内)设置presort=True通过对数据预处理来加快训练，但对于较大训练集而言，可能会减慢训练速度</li>\n",
    "</ui>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier属性说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>classes_</b>: </li>\n",
    "    <li><b>feature_importances_</b>: </li>\n",
    "    <li><b>max_features_</b>: </li>\n",
    "    <li><b>n_classes_</b>: </li>\n",
    "    <li><b>n_features_</b>: </li>\n",
    "    <li><b>n_outputs_</b>: </li>\n",
    "    <li><b>tree_</b>: </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV类说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV参数说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>estimator</b>: 估算器，继承于BaseEstimator</li>\n",
    "    <li><b>param_grid</b>: dict,键为参数名，值为该参数需要测试值选项</li>\n",
    "    <li><b>scoring</b>: default=None</li>\n",
    "    <li><b>fit_params</b>: </li>\n",
    "    <li><b>n_jobs</b>: 设置要并行运行的作业数，取值为None或1，None表示1 job,1表示all processors,default=None</li>\n",
    "    <li><b>cv</b>: 交叉验证的策略数，None或integer,None表示默认3-fold, integer指定“(分层)KFold”中的折叠数</li>\n",
    "    <li><b>verbose</b>: 输出日志类型</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV属性说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>cv_results_</b>: dict of numpy(masked) ndarray</li>\n",
    "    <li><b>best_estimator_</b>: </li>\n",
    "    <li><b>best_score_</b>: Mean cross-validated score of the best_estimator</li>\n",
    "    <li><b>best_params_</b>: </li>\n",
    "    <li><b>best_index_</b>: int,The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
    "        candidate parameter setting</li>\n",
    "    <li><b>scorer_</b>: </li>\n",
    "    <li><b>n_splits_</b>: The number of cross-validation splits (folds/iterations)</li>\n",
    "    <li><b>refit_time</b>: float</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>参考资料:</b>\n",
    "- (1)<机器学习实战基于Scikit-Learn和TensorFlow>\n",
    "- (2)<百面机器学习>\n",
    "- (3)李航<统计学习方法>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
