{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1)分别使用不带约束和带约束的最小二乘法对$y = f(x)$模型进行回归学习，x为d维实向量作为输入，y为实数值作为输出\n",
    "\n",
    "线性模式下：$f(x) = \\sum_{i=1}^d w_ix_i$,$w_i$为学习参数\n",
    "\n",
    "核模式下：$f(x) = \\sum_{i=1}^d w_i K(x,x_i)$,$w_i$为学习参数，$K(x,x_i)$为核函数\n",
    "\n",
    "- (2)寻找l1正则化产生稀疏性的解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不带约束的最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>损失函数:</b>\n",
    "$$J(W) = \\frac{1}{2}\\sum_{i=1}^d {(w_ix_i - y_i)}^2$$,矩阵方式表示为$$J(W) = \\frac{1}{2}{||W^T X - Y||}^2$$,推导：\n",
    "$$J(W) = \\frac{1}{2}(W^TX - Y){(W^T X - Y)}^T = \\frac{1}{2} (W^TXX^TW - W^T XY^T - YX^TW + YY^T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求J(W)对W的偏导：$$\\frac{\\partial J(W)}{\\partial W} = XX^TW - XY^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当偏导为0时，J(W)值最小，则$$XX^TW = XY^T$$\n",
    "当$XX^T$可逆时得：$$W = {(XX^T)}^{-1}XY^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加权最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令加权系数为$a_i$,则损失函数为：$$J(W) = \\frac{1}{2}\\sum_{i=1}^d {a_i(w_ix_i - y_i)}^2$$,矩阵方式表示为$$J(W) = \\frac{1}{2}{A^T||W^T X - Y||}^2$$,同样的方法得：$$W = {(XAX^T)}^{-1}XAY^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l1约束的最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单纯得最小二乘法对于包含噪音得学习过程经常有过拟合得弱点，这往往是由于模型相对于训练样本过度复杂导致的，为了优化过拟合的问题，可以采用带约束的最小二乘法\n",
    "\n",
    "定义l1范数优化问题：\n",
    "$$minJ(W) $$\n",
    "$$s.t {||W||}_1 <= R$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用拉格朗日对偶函数对上面的优化问题进行求解$$J(W,\\lambda) = \\frac{1}{2}{||W^T X - Y||}^2 + \\lambda {||W||}_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于${||W||}_1$当w_i = 0时不可以微分，所以我们就无法采用直接求导的方法了\n",
    "\n",
    "关于l1范数最小化算法有很多，可以参考博客：https://blog.csdn.net/weixin_41923961/article/details/80547313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l2约束的最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义l1范数优化问题：\n",
    "$$minJ(W) $$\n",
    "$$s.t {||W||}_2 <= R$$\n",
    "使用拉格朗日对偶函数对上面的优化问题进行求解$$J(W,\\lambda) = \\frac{1}{2}{||W^T X - Y||}^2 + \\frac{\\lambda}{2}({||W||}_2 - R)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求J(W)对W的偏导：$$\\frac{\\partial J(W)}{\\partial W} = XX^TW - XY^T + \\lambda W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当偏导为0时，J(W)值最小，则$$(XX^T+\\lambda I)W = XY^T$$\n",
    "$$W = {(XX^T+\\lambda I)}^{-1}XY^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I是单位矩阵，从上式看，在l2约束的最小二乘法中，通过$XX^T与\\lambda I$相加提高其正则性，进而可以更稳定地进行逆矩阵的求解，l2正则化的最小二乘法也称为岭回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最小二乘法的局限性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)最小二乘法求解过程中要注意'矩阵是否可逆'这个问题,当矩阵不可逆时，可以使用梯度下降法、正则化进行求解\n",
    "\n",
    "(2)当样本的特征(维度)非常大时，计算${(X^TX)}^{-1}$时非常耗时，甚至不可行。那这个n到底多大就不适合最小二乘法呢？如果你没有很多的分布式大数据计算资源，建议超过10000个特征就用迭代法吧，或者通过主成分分析降低特征的维度后再用最小二乘法\n",
    "\n",
    "(3)如果拟合函数不是线性的，这时无法使用最小二乘法，需要通过一些技巧转化为线性才能使用\n",
    "\n",
    "(4) 当样本量数据很少，小于特征数的时候，这时拟合方程是欠定的，常用的优化方法都无法去拟合数据。当样本数量等于特征数的时候，用方程组求解就可以了。当m大于n时，拟合方程是超定的，也就是我们常用与最小二乘法的场景了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l1正则化与稀疏性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 角度1:解空间形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 角度2:函数叠加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 角度3:贝叶斯先验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
