{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最小二乘学习法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设样本X,标签y,权重w如下：\n",
    "\n",
    "$X_{m*n} = \\left[\\begin{array}{cccc} \n",
    "    1&x_{11}&x_{12}&...&x_{1n}\\\\ \n",
    "    1&x_{21}&x_{22}&...&x_{2n}\\\\\n",
    "    1&...&...&...&...\\\\\n",
    "    1&x_{m1}&x_{m2}&...&x_{mn}\\\\ \n",
    "\\end{array}\\right] \n",
    "$\n",
    "\n",
    "$Y = (y_1,y_2...,y_m)^T$\n",
    "\n",
    "$W = (w_0,w_1,...,w_n)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最小二乘法是对模型的输出$X*W$和训练输出y的平方误差$$L(w) = \\frac{1}{2}\\sum_{i=1}^m{(X_i * W - Y_i)}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$X_i = (1,x_{i1},x_{i2},...,x_{in})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换成矩阵的形式$$L(w) = \\frac{1}{2}{||XW-Y||}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通最小二乘法算法推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(w) = \\frac{1}{2}(XW-Y)^T{XW-Y}$\n",
    "\n",
    "$L(w) = \\frac{1}{2}(W^TX^TXW - W^TX^TY - Y^TXW + Y^TY)$\n",
    "\n",
    "\n",
    "求L(W)的一阶偏导：\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w} = \\frac{1}{2}(2X^TXW - X^TY - X^TY)$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w} = X^TXW - X^TY$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果其偏导为0,则L(w)具有最小值，则$W =(X^TX)^{-1}X^TY$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：只有方阵和非奇异矩阵才能定义逆矩阵，可以通过计算行列式判断(X^TX)是否有逆矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加权最小二乘法学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对顺序为i的训练样本的平方差通过权重$\\theta_i >= 0$进行加权，然后再采用最小二乘法学习$$L(w) = \\frac{1}{2}\\sum_{i=1}^m{\\theta_i(X_i * W - Y_i)}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加权最小二乘学习法，与没有权重时相同$$W = (X^T\\theta X)^{-1}X^T\\theta Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过加权最小二乘学习法解决普通最小二乘法求逆的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l2约束的最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2约束的最小二乘学习法是以参数空间的原点为圆心，在给定一定半径范围的圆(一般为超球)内进行求解的，R表示的即是圆的半径,对原始最小二乘法进行约束来防止过拟合现象$$||W||{_2}^2 <= R$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lagrange优化问题：$$minimize \\frac{1}{2}{||XW-Y||}^2$$ $$s.t. ||W||{_2}^2 <= R$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lagrange函数：$$L(w,\\lambda) = \\frac{1}{2}{||XW-Y||}^2 + \\frac{\\lambda}{2}(||W||{_2}^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underline{max\\lambda minw}L(w,\\lambda) = X^TXW - X^TY + \\lambda W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过一阶偏导等于零$$W = (X^TX+\\lambda I)X^TY$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I是单位矩阵，在l2约束的最小二乘学习法中，通过将矩阵$X^TX$与$\\lambda I$相加提高其正则性，进而就可以稳定地进行逆矩阵求解"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
