{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> '没有测量，就没有科学'这是科学家门捷列夫的名言。在计算机科学特别是机器学习领域中，对模型的评估同样至关重要，只有选择与问题相匹配的评估方法，才能快速地发现模型选择或训练过程中出现的问题，迭代地对模型进行优化。模型评估主要分为离线评估和在线评估两个阶段。针对分类、排序、回归、序列预测等不同类型的机器学习问题，评估指标的选择也有所不同。知道每种评估指标的精确定义、有针对性地选择合适的评估指标、更具评估指标的反馈进行模型调整，这些都是模型评估阶段的关键问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率是指分类正确的样本占总样个数的比例：$$Accuracy = \\frac{n_{correct}}{n_{total}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n_{correct}$为被正确分类的样本个数，$n_{total}$为总样本的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>准确率的局限性:</b>准确率是分类问题中最简单也是最直观的评价指标，但存在明显的缺陷，当不同总类的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如：当负样本占99%,分类器把所有样本都预测为负样本也可以得到99%的准确率，换句话说总体准确率高，并不代表类别比例小的准确率高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精确率和召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精确率是指正确分类的正样本个数占分类器判定为正样本的样本个数的比例\n",
    "\n",
    "召回率是指正确分类的正样本个数占真正的正样本数的比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precison值和Recall值是既矛盾又统一的两个指标，为了提高Precison值，分类器需要尽量在‘更有把握’时才把样本预测为正样本，但此时往往会因为过于保守而漏掉很多‘没有把握’的正样本，导致Recall值降低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用TopN返回结果的Precision值和Recall值来衡量排序模型的性能，即认为模型返回的TopN的结果就是模型判定的正样本，然后计算N个位置上的Precision和前N个位置上的Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1分数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1分数是精度和召回率的谐波平均值，正常的平均值平等对待所有的值，而谐波平均值回给予较低的值更高的权重，因此，只有当召回率和精度都很高时，分类器才能得到较高的F1分数\n",
    "$$F_1 = \\frac{1}{\\frac{1}{精度}+\\frac{1}{召回率}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1分数对那些具有相近的精度和召回率的分类器更为有利。但这并不一定能符合你的期望，在某些情况下，你更关心的是精度，而另一些情况下，你可能真正关心的是召回率。精确率与召回率的权衡将是很值得思考的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 均方误差、根均方误差、绝对百分比误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "均方误差：$$MSE =\\frac{1}{n}\\sum_{i=1}^n(y_{pred} - y_i)^2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根均方误差：$$RMES = \\sqrt{MSE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>均方误差和根均方误差都会受到异常值的影响，而影响最终的模型评估</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均绝对百分比误差：$$MAPE = \\sum_{i=1}^n|\\frac{(y_{pred}-y_i)}{y_i}|*\\frac{100}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>平均绝对百分比误差提高了异常值的鲁棒性，相当于把每个点的误差进行了归一化处理，降低了个别离群带来的绝对误差的影响</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是ROC曲线？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二值分类器是机器学习领域中最常见也是应用最广泛的分类器。评价二值分类器的指标很多，比如precision,recall,F1 score,P-R曲线等，但发现这些指标或多或少只能反映模型在某一方面的性能，相比而言，ROC曲线则有很多优点，经常作为评估二值分类器最重要的指标之一"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC曲线是Receiver Operating Characteristic Curve的简称，中文名为'受试者工作特征曲线'\n",
    "\n",
    "ROC曲线的横坐标为假阳性率(FPR),纵坐标为真阳性率(TPR)，FPR和TPR的计算方法分别为:$$FPR = \\frac{FP}{N}$$ $$TPR = \\frac{TP}{P}$$\n",
    "P是真实的正样本数量，N是真实的负样本数量，TP是P个正样本中被分类器预测为正样本的个数，FP为N个负样本中被预测为正样本的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC曲线绘制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>创建数据集</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   真实标签  模型输出概率\n",
      "1     p   0.900\n",
      "2     p   0.800\n",
      "3     n   0.700\n",
      "4     p   0.600\n",
      "5     p   0.550\n",
      "6     p   0.540\n",
      "7     n   0.530\n",
      "8     n   0.520\n",
      "9     p   0.510\n",
      "10    n   0.505\n",
      "11    p   0.400\n",
      "12    p   0.390\n",
      "13    p   0.380\n",
      "14    n   0.370\n",
      "15    n   0.360\n",
      "16    n   0.350\n",
      "17    p   0.340\n",
      "18    n   0.330\n",
      "19    p   0.300\n",
      "20    n   0.100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_name = ['真实标签','模型输出概率']\n",
    "datasets = [['p',0.9],['p',0.8],['n',0.7],['p',0.6],\n",
    "           ['p',0.55],['p',0.54],['n',0.53],['n',0.52],\n",
    "           ['p',0.51],['n',0.505],['p',0.4],['p',0.39],\n",
    "           ['p',0.38],['n',0.37],['n',0.36],['n',0.35],\n",
    "           ['p',0.34],['n',0.33],['p',0.30],['n',0.1]]\n",
    "\n",
    "data = pd.DataFrame(datasets,index = [i for i in range(1,21,1)],columns=column_name)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>绘制ROC曲线</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 计算各种概率情况下对应的(假阳率，真阳率)\n",
    "points = {0.1:[1,1],0.3:[0.9,1],0.33:[0.9,0.9],0.34:[0.8,0.9],0.35:[0.8,0.8],\n",
    "        0.36:[0.7,0.8],0.37:[0.6,0.8],0.38:[0.5,0.8],0.39:[0.5,0.7],0.40:[0.4,0.7],\n",
    "        0.505:[0.4,0.6],0.51:[0.3,0.6],0.52:[0.3,0.5],0.53:[0.2,0.5],0.54:[0.1,0.5],\n",
    "        0.55:[0.1,0.4],0.6:[0.1,0.3],0.7:[0.1,0.2],0.8:[0,0.2],0.9:[0,0.1]}\n",
    "X = []\n",
    "Y = []\n",
    "for value in points.values():\n",
    "        X.append(value[0])\n",
    "        Y.append(value[1])\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X,Y,c = 'r',marker = 'o')\n",
    "plt.plot(X,Y)\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>AUC指ROC曲线下的面积大小，该值能够量化地反映基于ROC曲线衡量出的模型性能</b>,AUC越大说明分类器越可能把真正的正样本排在前面，分类性能越好\n",
    "\n",
    "ROC曲线相比P-R曲线，当正负样本的分布发生变化时，ROC曲线的形状能够保存基本不变，而P-R曲线的形状一般会发生激烈的变化，这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout检验是最简单也是最直接的验证方法，它将原始的样本随机划分为训练集和验证集两部分。sklearn.model_selction.train_test_split函数就是使用该方法。比方说，将样本按照70%-30%的比例分成两部分，70%的样本用于模型训练，30%的样本用于模型验证\n",
    "\n",
    "Holdout检验的缺点很明显，即在验证集上计算出来的评估指标与原始分组有很大关系，为了消除随机性，研究者们引入了'交叉验证'的思想"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-flod交叉验证:首先将全部样本划分成K个大小相等的样本子集，依次遍历这k个子集，每次把当前子集作为验证集，其余的子集作为训练集。最后把K次评估指标的平均值作为最终的评估指标，在实际实验中，K经常取10\n",
    "\n",
    "留一验证:每次留下一个样本作为验证集，其余所有样本作为测试集，样本总数为n,依次对n个样本进行遍历，进行n次验证，再将评估指标求平均值得到最终的评估指标，在样本总数较多的情况下，留一验证法的时间开销极大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自助法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不管是Holdout检验还是交叉验证，都是基于划分训练集和测试集的方法进行模型评估的，然而，当样本规模较小时，将样本集进行划分会让训练集进一步减少，这可能会影响模型训练效果，自助法是可以维持训练集样本规模的验证方法\n",
    "\n",
    "自助法是基于自助采样法的检验方法，对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集，n次采样过程中，有的样本会被重复采样，有的样本没有被抽到过，将这些没有被抽到过的样本作为训练集，进行模型验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了进行超参数调优，一般会采用网格搜索、随机搜索、贝叶斯优化等算法。超参数搜索算法一般包括以下几个要素:\n",
    "- (1)目标函数，即算法需要最大化/最小化的目标\n",
    "- (2)搜索范围，一般通过上限和下限来确定\n",
    "- (3)算法的其他参数，如搜索步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网格搜索可能是最简单、应用最广泛的超参数搜索算法，它通过查找搜索范围内的所有的点来确定最优值。如果采用较大的搜索范围以及较小的步长，网格搜索有很大概率找到全局最优解，然而这种搜索方案十分消耗计算资源和时间，特别是需要调优的超参数比较的时候，因此，在实际应用过程中，网格搜索法一般会先使用较大的搜索范围和较大的步长，来寻找全局最优解可能的位置，然后会逐渐缩小搜索范围和步长，来寻找更精确的最优值，这种操作方案可以降低所需的时间和计算量，但由于目标函数一般是非凸的，所有很可能会错过全局最优解，sklearn提供了GridSearchCV类实现网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机搜索的思想与网格搜索的思想比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点。它的理论依据是，如果样本点足够大，那么通过随机采样也能大概率地找到全局最优解或近似解，随机搜索一般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果也是没法保证的，sklearn提供了RandomizedSearchCV类实现随机搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯优化算法在寻找最优超参数时，采用了与网格搜索，随机搜索完全不同的方法，网格搜索和随机搜索在测试一个新点时，会忽略前一个点的信息，而贝叶斯优化算法则充分利用了之前的信息，贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它学习目标函数形状的方法是，首先根据先验分布，假设一个搜索函数，然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布，最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。\n",
    "\n",
    "对于贝叶斯优化算法，有一个需要注意的地方，一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值，为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，'探索'就是在还未取样的区域获取采样点，而'利用'则是根据后验分布在最可能出现全局最优值的区域进行采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降低过拟合风险的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1)从数据入手，后的更多的训练数据。使用更多的训练数据是解决过拟合问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减少噪音的影响，当然，直接增加实验数据一般是很困难的，但是可以通过一定的规则来扩充训练数据。比如，在图像分类的问题上，可以通过图像的平移、旋转、缩放等方式扩充数据；更进一步地，可以使用生成式对抗网络来合成大量的新训练数据\n",
    "- (2)降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免拟合过多的采样噪音。例如，在神经网络中减少网络层数、神经元个数等;在决策树模型中降低树的深度、进行剪枝等\n",
    "- (3)正则化方法\n",
    "- (4)集成学习方法。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降低欠拟合风险方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1)添加新特征。当特征不足或现有特征与样本标签的相关性不强时，模型容易出现不拟合，通过挖掘'上下文特征''ID类特征''组合特征'等新的特征，往往能够取得更好的效果，在深度学习的潮流中，有很多类型可以帮组完成特征工程，如因子分解机\n",
    "- (2)增加模型复杂度。简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有更强的拟合能力,例如，在线性模型中添加高次项，在神经网络模型中增加网络层数或神经元个数等\n",
    "- (3)减少正则化系数。正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要针对性地减少正则化系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>参考资料:</b>\n",
    "- (1)<机器学习实战基于Scikit-Learn和TensorFlow>\n",
    "- (2)<百面机器学习>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
