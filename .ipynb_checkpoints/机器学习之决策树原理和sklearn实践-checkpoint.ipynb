{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    决策树是一种基本的分类与回归方法，决策树模型呈树型结构，在分类问题中，表示基于特征对实例进行分类的过程，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布，其主要优点是模型具有可读性，分类速度快。决策树的学习通常包括三个步骤：特征选择、决策树的生成和决策树的修剪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3---最大信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的度量，设X是一个取有限个值的随机变量，其概率分布为：$$P(X=X_i)=P_i (i = 1,2,...,n)$$,则随机变量X的熵定义为：$$H(X) = -\\sum_{i=1}^np_i\\log{p_i}$$表达式中的对数以2为底或以e为底，这时熵的单位分别称作bit或nat,从表达式可以看出X的熵与X的取值无关，所以X的熵也记作$H(p)$,即$$H(p) = -\\sum_{x=1}^np_i\\log{p_i}$$熵取值越大，随机变量的不确定性越大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件熵：\n",
    "    \n",
    "条件熵H(Y|X)表示在已知随机变量X的条件下，随机变量Y的不确定性，随机变量X给定的条件下随机变量Y的条件熵定义为X给定条件下Y的条件概率分布的熵对X的数学期望$$H(Y|X) = \\sum_{i=1}^nP(X=X_i)H(Y|X=X_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益：$$g(D,A) = H(D) - H(D|A)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    年龄  长相  工资 写代码  类别\n",
      "小A   老   帅   高  不会  不见\n",
      "小B  年轻  一般  中等   会   见\n",
      "小C  年轻   丑   高  不会  不见\n",
      "小D  年轻  一般   高   会   见\n",
      "小L  年轻  一般   低  不会  不见\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "        '年龄':['老','年轻','年轻','年轻','年轻'],\n",
    "        '长相':['帅','一般','丑','一般','一般'],\n",
    "        '工资':['高','中等','高','高','低'],\n",
    "        '写代码':['不会','会','不会','会','不会'],\n",
    "        '类别':['不见','见','不见','见','不见']}\n",
    "frame = pd.DataFrame(data,index=['小A','小B','小C','小D','小L'])\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5108256237659907\n",
      "H(D): 0.9709505944546686\n",
      "H(D|年龄) 0.8\n",
      "以同样的方法计算H(D|长相),H(D|工资),H(D|写代码)\n",
      "H(D|长相) 0.551\n",
      "H(D|工资) 0.551\n",
      "H(D|写代码) 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(3/5))\n",
    "print('H(D):',-3/5 *math.log(3/5,2) - 2/5*math.log(2/5,2))\n",
    "print('H(D|年龄)',1/5*math.log(1,2)+4/5*(-1/2*math.log(1/2,2)-1/2*math.log(1/2,2)))\n",
    "print('以同样的方法计算H(D|长相),H(D|工资),H(D|写代码)')\n",
    "print('H(D|长相)',0.551)\n",
    "print('H(D|工资)',0.551)\n",
    "print('H(D|写代码)',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算信息增益：g(D,写代码)=0.971最大，可以先按照写代码来拆分决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5---最大信息增益比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的问题，使用信息增益比可以对对着问题进行校正，这是特征选择的另一标准\n",
    "信息增益比定义为其信息增益g(D,A)与训练数据集D关于特征A的值的熵$H_A(D)$之比：$$g_R(D,A) = \\frac{g(D,A)}{H_A(D)}$$\n",
    "\n",
    "$$H_A(D) = -\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\log\\frac{|D_i|}{|D|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿上面ID3的例子说明：\n",
    "$$H_年龄(D) = -1/5*math.log(1/5,2)-4/5*math.log(4/5,2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g_R(D,年龄) = H_{年龄}(D)/g(D,年龄) = 0.171/0.722 = 0.236 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART----最大基尼指数(Gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini描述的是数据的纯度，与信息熵含义类似,分类问题中，假设有K个类，样本点数据第k类的概率为$P_k$,则概率分布的基尼指数定义为：\n",
    "$$Gini(p) = 1- \\sum_{k=1}^Kp_k(1-p_k) = 1 - \\sum_{k=1}^Kp_{k}^2$$\n",
    "对于二分类问题，弱样本点属于第1个类的概率是p,则概率分布的基尼指数为$$Gini(p) = 2p(1-p)$$,对于给定的样本几何D,其基尼指数为$$Gini(D) = 1 - \\sum_{k=1}^K[\\frac{|C_k|}{|D|}]^2$$注意这里$C_k$是D种属于第k类的样本子集，K是类的个数,如果样本几个D根据特征A是否取某一可能指a被分割成D1和D2两部分，则在特征A的条件下，集合D的基尼指数定义为$$Gini(D,A) = \\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)$$\n",
    "$$Gini(D|年龄=老)=1/5*（1-1）+4/5*[1-(1/2*1/2+1/2*1/2)] = 0.4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART在每一次迭代种选择基尼指数最小的特征及其对应的切分点进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3、C4.5与Gini的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从样本类型角度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从样本类型角度，ID3只能处理离散型变量，而C4.5和CART都处理连续性变量，C4.5处理连续性变量时，通过对数据排序之后找到类别不同的分割线作为切割点，根据切分点把连续型数学转换为bool型，从而将连续型变量转换多个取值区间的离散型变量。而对于CART，由于其构建时每次都会对特征进行二值划分，因此可以很好地适合连续性变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从应用角度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3和C4.5只适用于分类任务，而CART既可以用于分类也可以用于回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从实现细节、优化等角度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3对样本特征缺失值比较敏感，而C4.5和CART可以对缺失值进行不同方式的处理，ID3和C4.5可以在每个结点熵产生出多叉分支，且每个特征在层级之间不会复用，而CART每个结点只会产生两个分支，因此会形成一颗二叉树，且每个特征可以被重复使用；ID3和C4.5通过剪枝来权衡树的准确性和泛化能力，而CART直接利用全部数据发现所有可能的树结构进行对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么要进行剪枝？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    对决策树进行剪枝是为了防止过拟合\n",
    "    \n",
    "    根据决策树生成算法通过训练数据集生成了复杂的决策树，导致对于测试数据集出现了过拟合现象，为了解决过拟合，就必须考虑决策树的复杂度，对已生成的决策树进行剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪枝算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C_a(T) = \\sum_{t=1}^{|T|}N_tH_t(T) + a|T|$$\n",
    "\n",
    "$其中|T|为叶结点个数，N_t为结点t的样本个数，H_t(T)为结点t的信息熵，a|T|为惩罚项，a>=0$\n",
    "\n",
    "$$C_a(T) = \\sum_{t=1}^{|T|}N_tH_t(T) + a|T| = -\\sum_{t=1}^{|T|}\\sum_{k=1}^KN_{tk}\\log \\frac{N_{tk}}{N_t} + a|T|$$\n",
    "\n",
    "注意：上面的公式中是$N_{tk}\\log \\frac{N_{tk}}{N_t}$,而不是$\\frac{N_{tk}}{N_t} \\log \\frac{N_{tk}}{N_t}$\n",
    "\n",
    "令：$$C_a(T) = C(T) + a|T|$$\n",
    "\n",
    "$C(T)$表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，|T|表示模型复杂度，参数a>=0控制两者的影响力，较大的a促使选择较简单的模型，较小的a促使选择复杂的模型，a=0意味着只考虑模型与训练数据的拟合程度，不考虑模型的复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.tree.DecisionTreeClassifier类说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecsisionTreeClassifier类参数说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ui>\n",
    "    <li><b>criterion</b>: 特征选择方式，string,('gini' or 'entropy'),default='gini'</li>\n",
    "    <li><b>splitter</b>: 每个结点的拆分策略，('best' or 'random'),string,default='best'</li>\n",
    "    <li><b>max_depth</b>: int,default=None</li>\n",
    "    <li><b>min_samples_split</b>: int,float,default=2,分割前所需的最小样本数</li>\n",
    "    <li><b>min_samples_leaf</b>: </li>\n",
    "    <li><b>min_weight_fraction_leaf</b>: </li>\n",
    "    <li><b>max_features</b>: </li>\n",
    "    <li><b>random_state</b>: </li>\n",
    "    <li><b>max_leaf_nodes</b>: </li>\n",
    "    <li><b>min_impurity_decrease</b>: </li>\n",
    "    <li><b>min_impurity_split</b>: </li>\n",
    "    <li><b>class_weight</b>: </li>\n",
    "    <li><b>presort</b>: bool,default=False,对于小型数据集(几千个以内)设置presort=True通过对数据预处理来加快训练，但对于较大训练集而言，可能会减慢训练速度</li>\n",
    "</ui>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier属性说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>classes_</b>: </li>\n",
    "    <li><b>feature_importances_</b>: </li>\n",
    "    <li><b>max_features_</b>: </li>\n",
    "    <li><b>n_classes_</b>: </li>\n",
    "    <li><b>n_features_</b>: </li>\n",
    "    <li><b>n_outputs_</b>: </li>\n",
    "    <li><b>tree_</b>: </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为卫星数据集训练并微调一个决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a.使用make_moons(n_samples=10000,noise=0.4)生成一个卫星数据集\n",
    "- b.使用train_test_split()拆分训练集和测试集\n",
    "- c.使用交叉验证的网格搜索为DecisionTreeClassifier找到合适的超参数，提示:尝试max_leaf_nodes的多种值\n",
    "- d.使用超参数对整个训练集进行训练，并测量模型测试集上的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(array([[ 0.24834453, -0.11160162],\n",
      "       [-0.34658051, -0.43774172],\n",
      "       [-0.25009951, -0.80638312],\n",
      "       ...,\n",
      "       [ 2.3278198 ,  0.39007769],\n",
      "       [-0.77964208,  0.68470383],\n",
      "       [ 0.14500963,  1.35272533]]), array([1, 1, 1, ..., 1, 0, 0], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "dataset = make_moons(n_samples=10000,noise=0.4)\n",
    "print(type(dataset))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2) (10000,)\n"
     ]
    }
   ],
   "source": [
    "dataset_array = np.array(dataset[0])\n",
    "label_array = np.array(dataset[1])\n",
    "print(dataset_array.shape,label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2) (2000, 2)\n",
      "(8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# 拆分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test = train_test_split(dataset_array,test_size=0.2,random_state=42)\n",
    "print(x_train.shape,x_test.shape)\n",
    "y_train,y_test = train_test_split(label_array,test_size=0.2,random_state=42)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] max_leaf_nodes=2 ................................................\n",
      "[CV] ................................. max_leaf_nodes=2, total=   0.0s\n",
      "[CV] max_leaf_nodes=2 ................................................\n",
      "[CV] ................................. max_leaf_nodes=2, total=   0.0s\n",
      "[CV] max_leaf_nodes=2 ................................................\n",
      "[CV] ................................. max_leaf_nodes=2, total=   0.0s\n",
      "[CV] max_leaf_nodes=3 ................................................\n",
      "[CV] ................................. max_leaf_nodes=3, total=   0.0s\n",
      "[CV] max_leaf_nodes=3 ................................................\n",
      "[CV] ................................. max_leaf_nodes=3, total=   0.0s\n",
      "[CV] max_leaf_nodes=3 ................................................\n",
      "[CV] ................................. max_leaf_nodes=3, total=   0.0s\n",
      "[CV] max_leaf_nodes=4 ................................................\n",
      "[CV] ................................. max_leaf_nodes=4, total=   0.0s\n",
      "[CV] max_leaf_nodes=4 ................................................\n",
      "[CV] ................................. max_leaf_nodes=4, total=   0.0s\n",
      "[CV] max_leaf_nodes=4 ................................................\n",
      "[CV] ................................. max_leaf_nodes=4, total=   0.0s\n",
      "[CV] max_leaf_nodes=5 ................................................\n",
      "[CV] ................................. max_leaf_nodes=5, total=   0.0s\n",
      "[CV] max_leaf_nodes=5 ................................................\n",
      "[CV] ................................. max_leaf_nodes=5, total=   0.0s\n",
      "[CV] max_leaf_nodes=5 ................................................\n",
      "[CV] ................................. max_leaf_nodes=5, total=   0.0s\n",
      "[CV] max_leaf_nodes=6 ................................................\n",
      "[CV] ................................. max_leaf_nodes=6, total=   0.0s\n",
      "[CV] max_leaf_nodes=6 ................................................\n",
      "[CV] ................................. max_leaf_nodes=6, total=   0.0s\n",
      "[CV] max_leaf_nodes=6 ................................................\n",
      "[CV] ................................. max_leaf_nodes=6, total=   0.0s\n",
      "[CV] max_leaf_nodes=7 ................................................\n",
      "[CV] ................................. max_leaf_nodes=7, total=   0.0s\n",
      "[CV] max_leaf_nodes=7 ................................................\n",
      "[CV] ................................. max_leaf_nodes=7, total=   0.0s\n",
      "[CV] max_leaf_nodes=7 ................................................\n",
      "[CV] ................................. max_leaf_nodes=7, total=   0.0s\n",
      "[CV] max_leaf_nodes=8 ................................................\n",
      "[CV] ................................. max_leaf_nodes=8, total=   0.0s\n",
      "[CV] max_leaf_nodes=8 ................................................\n",
      "[CV] ................................. max_leaf_nodes=8, total=   0.0s\n",
      "[CV] max_leaf_nodes=8 ................................................\n",
      "[CV] ................................. max_leaf_nodes=8, total=   0.0s\n",
      "[CV] max_leaf_nodes=9 ................................................\n",
      "[CV] ................................. max_leaf_nodes=9, total=   0.0s\n",
      "[CV] max_leaf_nodes=9 ................................................\n",
      "[CV] ................................. max_leaf_nodes=9, total=   0.0s\n",
      "[CV] max_leaf_nodes=9 ................................................\n",
      "[CV] ................................. max_leaf_nodes=9, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用交叉验证的网格搜索为DecisionTreeClassifier找到合适的超参数\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(criterion='gini')\n",
    "param_grid = {'max_leaf_nodes': [i for i in range(2,10)]}\n",
    "gridSearchCV = GridSearchCV(decisionTree,param_grid=param_grid,cv=3,verbose=2)\n",
    "gridSearchCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_leaf_nodes': 4}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearchCV.best_params_)\n",
    "decision_tree = gridSearchCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8455\n"
     ]
    }
   ],
   "source": [
    "# 使用测试集对模型进行评估\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_prab = gridSearchCV.predict(x_test)\n",
    "print('accuracy_score:',accuracy_score(y_test,y_prab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(decision_tree,\n",
    "               out_file='./tree.dot',\n",
    "               rounded = True,\n",
    "               filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成tree.dot文件，然后使用dot命令$$dot -Tpng tree.dot -o decisontree_moons.png$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./datasets/decisiontree_moons.png' width=600 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV类说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV参数说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>estimator</b>: 估算器，继承于BaseEstimator</li>\n",
    "    <li><b>param_grid</b>: dict,键为参数名，值为该参数需要测试值选项</li>\n",
    "    <li><b>scoring</b>: default=None</li>\n",
    "    <li><b>fit_params</b>: </li>\n",
    "    <li><b>n_jobs</b>: 设置要并行运行的作业数，取值为None或1，None表示1 job,1表示all processors,default=None</li>\n",
    "    <li><b>cv</b>: 交叉验证的策略数，None或integer,None表示默认3-fold, integer指定“(分层)KFold”中的折叠数</li>\n",
    "    <li><b>verbose</b>: 输出日志类型</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV属性说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>cv_results_</b>: dict of numpy(masked) ndarray</li>\n",
    "    <li><b>best_estimator_</b>: </li>\n",
    "    <li><b>best_score_</b>: Mean cross-validated score of the best_estimator</li>\n",
    "    <li><b>best_params_</b>: </li>\n",
    "    <li><b>best_index_</b>: int,The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
    "        candidate parameter setting</li>\n",
    "    <li><b>scorer_</b>: </li>\n",
    "    <li><b>n_splits_</b>: The number of cross-validation splits (folds/iterations)</li>\n",
    "    <li><b>refit_time</b>: float</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
